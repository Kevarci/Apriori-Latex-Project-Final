{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from scipy.sparse import csr_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras transacciones:\n",
      "[['Organic Celery Hearts', 'Organic 4% Milk Fat Whole Milk Cottage Cheese', 'Bag of Organic Bananas', 'Organic Whole String Cheese', 'Lightly Smoked Sardines in Olive Oil', 'Organic Hass Avocado', 'Bulgarian Yogurt', 'Cucumber Kirby'], ['Spring Water', 'Prosciutto, Americano', 'Grated Pecorino Romano Cheese', 'Super Greens Salad', 'Cage Free Extra Large Grade AA Eggs', 'Asparagus', 'Organic Garnet Sweet Potato (Yam)', 'Organic Half & Half'], ['Organic Raw Unfiltered Apple Cider Vinegar', 'Shelled Pistachios', 'Organic Biologique Limes', 'Organic Baby Arugula', 'Organic Hot House Tomato', 'Bunched Cilantro', 'Green Peas', 'Fresh Dill', 'Flat Parsley, Bunch'], ['Roasted Turkey', 'Organic Whole Strawberries', 'Organic Pomegranate Kernels', 'Organic Raspberries', 'Organic Cucumber', 'Organic Blueberries', 'Organic Grape Tomatoes'], ['Organic Whole Grassmilk Milk', 'Garbanzo Beans', 'Geranium Liquid Dish Soap', 'Corn Maize Tortillas', 'Organic Chocolate Almondmilk Pudding', 'Pinto Beans No Salt Added', 'Natural Spring Water', 'Organic 2% Buttermilk', 'Uncured Applewood Smoked Bacon', 'Bag of Organic Bananas', 'Organic Extra Virgin Oil Olive', 'Organic Cinnamon Apple Sauce', 'Plastic Wrap', '100% Organic Unbleached All-Purpose Flour', 'Organic Ketchup', 'Organic Orange Juice With Calcium & Vitamin D', 'Mild Diced Green Chiles', 'Organic Yellow Onion', 'Organic Garlic', 'Organic Coconut Milk', 'Organic Lemonade', 'Uncured Genoa Salami', 'Organic Seasoned Yukon Select Potatoes Hashed Browns', 'Black Beans No Salt Added', 'Organic Raspberries', 'Organic Raw Kombucha Gingerade', 'Aluminum Foil', 'Olive Oil & Aloe Vera Hand Soap', 'Tomatoes, Crushed, Organic', 'Organic Italian Parsley Bunch', 'Black Beans', 'Organic Unsweetened Almond Milk', 'Organic Corn Starch', 'Organic Hothouse Cucumbers', 'Organic Sliced Provalone Cheese', 'Guacamole', 'Raspberry Sorbet Pops', 'Plastic Spoons', 'Crackers, Oyster', 'Whole Milk Greek Blended Vanilla Bean Yogurt', 'Organic Stringles Mozzarella String Cheese', 'Organic Zucchini', 'Sliced Pepperoni', 'Baby Swiss Slices Cheese', 'Lavender Scent Laundry Detergent', 'Organic Free Range Chicken Broth', 'Queso Fresco', 'Unsalted Cultured Butter', 'Natural Chicken & Maple Breakfast Sausage Patty']]\n"
     ]
    }
   ],
   "source": [
    "products = pd.read_csv('order_products__train.csv')\n",
    "orders = pd.read_csv('products.csv')\n",
    "\n",
    "dfMerged = pd.merge(orders, products, on=\"product_id\", how=\"inner\")\n",
    "\n",
    "# Agrupar productos por transacción para crear listas de transacciones\n",
    "\n",
    "transactions = dfMerged.groupby(\"order_id\")[\"product_name\"].apply(list).tolist()\n",
    "print(f\"Primeras transacciones:\\n{transactions[:5]}\")\n",
    "\n",
    "item_mapping = {item: idx for idx, item in enumerate(sorted(set(item for transaction in transactions for item in transaction)))}\n",
    "rows, cols = [], []\n",
    "for row_idx, transaction in enumerate(transactions):\n",
    "    for item in transaction:\n",
    "        rows.append(row_idx)\n",
    "        cols.append(item_mapping[item])\n",
    "\n",
    "# Crear la matriz dispersa\n",
    "order_matrix_sparse = csr_matrix(([1] * len(rows), (rows, cols)), shape=(len(transactions), len(item_mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular soporte de elementos individuales\n",
    "def calculate_support(item_indices, data_matrix):\n",
    "    \"\"\" Calcula el soporte de un conjunto de ítems. \"\"\"\n",
    "    item_mask = data_matrix[:, item_indices].toarray().all(axis=1)\n",
    "    support = np.sum(item_mask) / data_matrix.shape[0]\n",
    "    return support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar ítems frecuentes utilizando matrices dispersas\n",
    "def apriori_manual(data_matrix, min_support):\n",
    "    \"\"\" Implementación del algoritmo Apriori optimizada. \"\"\"\n",
    "    num_items = data_matrix.shape[1]\n",
    "    frequent_itemsets = []\n",
    "    current_itemsets = [[i] for i in range(num_items)]\n",
    "    \n",
    "    while current_itemsets:\n",
    "        next_itemsets = []\n",
    "        item_supports = []\n",
    "        \n",
    "        # Calcular soporte para cada conjunto actual\n",
    "        for itemset in current_itemsets:\n",
    "            support = calculate_support(itemset, data_matrix)\n",
    "            if support >= min_support:\n",
    "                frequent_itemsets.append((itemset, support))\n",
    "                item_supports.append(itemset)\n",
    "        \n",
    "        # Generar nuevas combinaciones de ítems frecuentes actuales\n",
    "        for i in range(len(item_supports)):\n",
    "            for j in range(i + 1, len(item_supports)):\n",
    "                combined_itemset = sorted(set(item_supports[i]) | set(item_supports[j]))\n",
    "                if len(combined_itemset) == len(item_supports[i]) + 1:\n",
    "                    next_itemsets.append(combined_itemset)\n",
    "        \n",
    "        current_itemsets = next_itemsets  # Actualizar conjuntos actuales\n",
    "    \n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.2 GiB for an array with shape (131209, 39123) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Medir tiempo con mlxtend.apriori\u001b[39;00m\n\u001b[32m      5\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m frequent_itemsets_apriori = apriori(pd.DataFrame(\u001b[43morder_matrix_sparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns=item_mapping.keys()), \n\u001b[32m      7\u001b[39m                                     min_support=min_support, use_colnames=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m mlxtend_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\sparse\\_compressed.py:1170\u001b[39m, in \u001b[36m_cs_matrix.toarray\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1169\u001b[39m     order = \u001b[38;5;28mself\u001b[39m._swap(\u001b[33m'\u001b[39m\u001b[33mcf\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out.flags.c_contiguous \u001b[38;5;129;01mor\u001b[39;00m out.flags.f_contiguous):\n\u001b[32m   1172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mOutput array must be C or F contiguous\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\sparse\\_base.py:1367\u001b[39m, in \u001b[36m_spbase._process_toarray_args\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 38.2 GiB for an array with shape (131209, 39123) and data type int64"
     ]
    }
   ],
   "source": [
    "# Ajustar los umbrales para balancear calidad y rendimiento\n",
    "min_support = 0.01  # Ajusta según la calidad de reglas requerida\n",
    "\n",
    "# Medir tiempo con mlxtend.apriori\n",
    "start_time = time.time()\n",
    "frequent_itemsets_apriori = apriori(pd.DataFrame(order_matrix_sparse.toarray(), columns=item_mapping.keys()), \n",
    "                                    min_support=min_support, use_colnames=True)\n",
    "mlxtend_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Medir tiempo con Apriori manual optimizado\u001b[39;00m\n\u001b[32m      2\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m frequent_itemsets_manual = \u001b[43mapriori_manual\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_matrix_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m sparse_time = time.time() - start_time\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFrecuentes calculados manualmente: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(frequent_itemsets_manual)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m conjuntos.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mapriori_manual\u001b[39m\u001b[34m(data_matrix, min_support)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Calcular soporte para cada conjunto actual\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m itemset \u001b[38;5;129;01min\u001b[39;00m current_itemsets:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     support = \u001b[43mcalculate_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m support >= min_support:\n\u001b[32m     16\u001b[39m         frequent_itemsets.append((itemset, support))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcalculate_support\u001b[39m\u001b[34m(item_indices, data_matrix)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_support\u001b[39m(item_indices, data_matrix):\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Calcula el soporte de un conjunto de ítems. \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     item_mask = \u001b[43mdata_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_indices\u001b[49m\u001b[43m]\u001b[49m.toarray().all(axis=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     support = np.sum(item_mask) / data_matrix.shape[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m support\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\sparse\\_index.py:80\u001b[39m, in \u001b[36mIndexMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     78\u001b[39m         res = \u001b[38;5;28mself\u001b[39m._get_sliceXslice(row, col)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m col.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_sliceXarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mindex results in >2 dimensions\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\sparse\\_csr.py:265\u001b[39m, in \u001b[36m_csr_base._get_sliceXarray\u001b[39m\u001b[34m(self, row, col)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_sliceXarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col):\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_major_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_minor_index_fancy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\sparse\\_compressed.py:856\u001b[39m, in \u001b[36m_cs_matrix._minor_index_fancy\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    854\u001b[39m res_indices = np.empty(nnz, dtype=idx_dtype)\n\u001b[32m    855\u001b[39m res_data = np.empty(nnz, dtype=\u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m \u001b[43mcsr_column_index2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_offsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m((res_data, res_indices, res_indptr),\n\u001b[32m    859\u001b[39m                       shape=new_shape, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Medir tiempo con Apriori manual optimizado\n",
    "start_time = time.time()\n",
    "frequent_itemsets_manual = apriori_manual(order_matrix_sparse, min_support)\n",
    "sparse_time = time.time() - start_time\n",
    "\n",
    "print(f\"Frecuentes calculados manualmente: {len(frequent_itemsets_manual)} conjuntos.\")\n",
    "print(f\"Tiempo con mlxtend.apriori: {mlxtend_time:.2f} segundos\")\n",
    "print(f\"Tiempo con matriz dispersa (manual): {sparse_time:.2f} segundos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar métricas de las reglas\n",
    "def generate_rules(frequent_itemsets, min_confidence):\n",
    "    \"\"\" Generar reglas de asociación. \"\"\"\n",
    "    rules = []\n",
    "    for itemset, support in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(len(itemset)):\n",
    "                antecedent = itemset[:i] + itemset[i+1:]\n",
    "                consequent = [itemset[i]]\n",
    "                antecedent_support = calculate_support(antecedent, order_matrix_sparse)\n",
    "                \n",
    "                # Calcular confianza y lift\n",
    "                if antecedent_support > 0:\n",
    "                    confidence = support / antecedent_support\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append({\n",
    "                            'antecedent': antecedent,\n",
    "                            'consequent': consequent,\n",
    "                            'support': support,\n",
    "                            'confidence': confidence\n",
    "                        })\n",
    "    return rules\n",
    "\n",
    "min_confidence = 0.3\n",
    "rules = generate_rules(frequent_itemsets_manual, min_confidence)\n",
    "print(f\"Reglas generadas: {len(rules)}\")\n",
    "for rule in rules[:5]:  # Mostrar las primeras reglas\n",
    "    print(f\"Regla: {rule}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
